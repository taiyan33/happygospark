{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "\n",
    "a = [1,2,3,'qoo', 4]\n",
    "a = [1,3,5,7,9]\n",
    "b = [2,4,6,8,10]\n",
    "\n",
    "res = []\n",
    "for i in range(0, len(a)):\n",
    "    res.append(a[i] * b[i])\n",
    "print(res)\n",
    "\n",
    "res = []\n",
    "for i,j in zip(a,b):\n",
    "    res.append(i * j)\n",
    "print(res)\n",
    "\n",
    "\n",
    "[i*j for i,j in zip(a,b)]\n",
    "\n",
    "\n",
    "import numpy \n",
    "na = numpy.array(a)\n",
    "nb = numpy.array(b)\n",
    "\n",
    "na * nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "\n",
    "import pandas\n",
    "sa = pandas.Series([1,2,3,4,5], index = ['a', 'b', 'c', 'd', 'e'])\n",
    "sa['a']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([['frank', 'M', 29], ['mary', 'F', 23], ['tom', 'M', 35], ['ted', 'M', 33], ['jean', 'F', 21], ['lisa', 'F', 20]])\n",
    "#df.info()\n",
    "#print(df)\n",
    "df.columns = ['name', 'gender', 'age']\n",
    "#print(df)\n",
    "\n",
    "#df.loc[[0,1,2] , ['name', 'gender'] ]\n",
    "\n",
    "df['age'].mean()\n",
    "df['age'].max()\n",
    "df['age'].min()\n",
    "df['age'].describe()\n",
    "\n",
    "df['age'][0]\n",
    "\n",
    "df['age'][0:3]\n",
    "\n",
    "\n",
    "df.describe()\n",
    "df.iloc[0]\n",
    "df.iloc[0:3]\n",
    "\n",
    "df['name']\n",
    "\n",
    "df[['name', 'age']]\n",
    "\n",
    "df[df['gender'] == 'M']\n",
    "df.loc[df['gender'] == 'M',  ['name', 'age']  ]\n",
    "\n",
    "df.loc[df['gender'] == 'F',  ['age']  ].mean()\n",
    "df.loc[df['gender'] == 'M',  ['age']  ].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PySpark DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register SqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql import SQLContext \n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "df = sqlContext.createDataFrame(row_data)\n",
    "df.registerTempTable(\"ratings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark DataFrame Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "#df.take(5)\n",
    "#df.show(10)\n",
    "df.select('userid', 'rating').groupBy('userid').avg().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "df.registerTempTable(\"ratings\")\n",
    "ratings_data = sqlContext.sql(\"\"\"\n",
    "     SELECT itemid,avg(rating) as avg_rating  from ratings group by itemid order by avg_rating desc \n",
    "\"\"\")\n",
    "ratings_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use toPandas to Convert Spark DataFrame Back To Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "pandas_df = ratings_data.toPandas()\n",
    "pandas_df.columns = ['itemid', 'sum_rating']\n",
    "pandas_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use rdd to Transform Spark DataFrame Back to RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "ratings_out = ratings_data.rdd.map(lambda p : 'itemid:{} - average rating: {}'.format(p.itemid, p.avg_rating))\n",
    "for ele in ratings_out.take(3):\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count DataFrame Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "ratings_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)]) \n",
    "y = sc.parallelize([(\"a\", 2), (\"a\", 3)])\n",
    "z = x.join(y)\n",
    "res = z.collect()\n",
    "sorted(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)]) \n",
    "y = sc.parallelize([(\"a\", 2)]) \n",
    "sorted(x.leftOuterJoin(y).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "y = sc.parallelize([(\"a\", 2)]) \n",
    "sorted(y.rightOuterJoin(x).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "x = sc.parallelize([(\"a\", 1), (\"b\", 4)])\n",
    "y = sc.parallelize([(\"a\", 2), (\"c\", 8)]) \n",
    "sorted(x.fullOuterJoin(y).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table Join By PySpark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.sql import SQLContext \n",
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "ratings = sc.textFile('file:/tmp/u.data', 4)\n",
    "ratings_data = ratings.map(lambda l:l.split())\n",
    "ratings_row_data = ratings_data.map(lambda p: \n",
    "    Row( userid=p[0], movieid=p[1], rating=int(p[2]) )\n",
    ")\n",
    "ratings_row_data.take(4)\n",
    "\n",
    "df = sqlContext.createDataFrame(ratings_row_data)\n",
    "df.registerTempTable(\"ratings\")\n",
    "\n",
    "movies = sc.textFile('file:/tmp/u.item', 4)\n",
    "\n",
    "movies_data = movies.map(lambda l:l.split('|'))\n",
    "#movies_data.take(3)\n",
    "movies_row_data = movies_data.map(lambda p: \n",
    "    Row(movieid=p[0], moviename=p[1] )\n",
    ")\n",
    "movies_row_data.take(4)\n",
    "\n",
    "ratings_df = sqlContext.createDataFrame(ratings_row_data)\n",
    "ratings_df.registerTempTable(\"ratings\")\n",
    "\n",
    "movies_df = sqlContext.createDataFrame(movies_row_data)\n",
    "movies_df.registerTempTable(\"movies\")\n",
    "\n",
    "best_movies = sqlContext.sql(\"\"\"\n",
    "     SELECT moviename,avg(rating) as avg_rating, count(1) as cnt  from movies inner join ratings on ratings.movieid = movies.movieid group by moviename order by  avg(rating) desc limit 10\n",
    "\"\"\")\n",
    "best_movies.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "m = ratings_df.join(movies_df, movies_df.movieid == ratings_df.movieid) \\\n",
    "  .groupBy(movies_df.moviename).agg({\"rating\": \"avg\"})\n",
    "m.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料預處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "raw_data = sc.textFile('file:/tmp/customer_churn.csv')\n",
    "raw_data.take(3)\n",
    "header = raw_data.first()\n",
    "skip_data = raw_data.filter(lambda line: line != header)\n",
    "\n",
    "skip_data.take(3)\n",
    "splitlines = skip_data.map(lambda l: l.split(\",\"))\n",
    "\n",
    "splitlines.take(3)\n",
    "\n",
    "def parseLine(col):\n",
    "    features = []\n",
    "    churn    = col[-1] \n",
    "    international  = 0 if col[4] == '\"no\"' else 1\n",
    "    voice          = 0 if col[5] == '\"no\"' else 1\n",
    "    label          = 0 if churn  == '\"no\"' else 1\n",
    "    features.append(international)\n",
    "    features.append(voice)\n",
    "    features += col[6:-1]\n",
    "    return LabeledPoint(label, Vectors.dense(features) )\n",
    "    \n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "trainData = splitlines.map(parseLine)\n",
    "#trainData.take(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "       \n",
    "model = DecisionTree.trainClassifier(trainData, numClasses=2, categoricalFeaturesInfo={},\n",
    "impurity='gini', maxDepth=5)\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 繪製決策樹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "print(\"Learned classification tree model:\") \n",
    "print(model.toDebugString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 單筆資料預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "head = trainData.first()\n",
    "head\n",
    "model.predict(head.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生批次預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "predictions = model.predict(trainData.map(lambda p:\n",
    "p.features))\n",
    "predictions.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評估準確度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "labels_and_preds = trainData.map(lambda p: p.label).zip(predictions)\n",
    "#labels_and_preds.take(100)\n",
    "filtered_labels_and_preds = labels_and_preds.filter(lambda v : v[0] == v[1]) \n",
    "test_accuracy = filtered_labels_and_preds.count() / float(trainData.count())\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from collections import Counter\n",
    "c = Counter(labels_and_preds.collect())\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算 AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "metrics = BinaryClassificationMetrics(labels_and_preds)\n",
    "#print(dir(metrics))\n",
    "\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR) \n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拿randomforest 進行評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pyspark\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "model = RandomForest.trainRegressor(trainData, categoricalFeaturesInfo={},\n",
    "                                    numTrees=100, featureSubsetStrategy=\"auto\",\n",
    "                                    impurity='variance', maxDepth=5)\n",
    "predictions = model.predict(trainData.map(lambda p:\n",
    "p.features))\n",
    "labels_and_preds = trainData.map(lambda p: p.label).zip(predictions)\n",
    "metrics = BinaryClassificationMetrics(labels_and_preds)\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR) \n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生訓練與測試資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dataset = trainData.randomSplit([0.7,0.3])\n",
    "trainset = train_test_dataset[0]\n",
    "testset  = train_test_dataset[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 根據訓練資料集建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree.trainClassifier(trainset, numClasses=2, categoricalFeaturesInfo={},\n",
    "impurity='gini', maxDepth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用測試資料集驗證模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testset.map(lambda p:\n",
    "p.features))\n",
    "labels_and_preds = testset.map(lambda p: p.label).zip(predictions)\n",
    "metrics = BinaryClassificationMetrics(labels_and_preds)\n",
    "\n",
    "print(\"Area under PR = %s\" % metrics.areaUnderPR) \n",
    "print(\"Area under ROC = %s\" % metrics.areaUnderROC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
